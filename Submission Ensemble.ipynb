{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "sys.path.append(\"./Torchvision/src\")\n",
    "from submission import model_submission, get_test_outputs, select_bboxes, format_results\n",
    "from models import get_model_detection\n",
    "sys.path.append(\"./Ensemble/ensemble-objdet/\")\n",
    "from legacy_ensemble import ensemble_legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First:\n",
    "\n",
    "- Check the selection. Make sure we select highest scores: argsort on the scores.\n",
    "\n",
    "### Soumettre:\n",
    " - base .7\n",
    " - nms_all(base, iou_thr=.5) .7\n",
    " - legacy_ensemble(results, iou_thr=.5) .7\n",
    " - nms_ensemble(results, iou_thr=.5) .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_eval_format(results):\n",
    "    out_results = {}\n",
    "    for k in results:\n",
    "        out_results[k] = {\n",
    "            \"dt_lbl\"   : results[k][\"labels\"].cpu().numpy(),\n",
    "            \"dt_bbox\"  : results[k][\"boxes\"].cpu().numpy(),\n",
    "            \"dt_score\" : results[k][\"scores\"].cpu().numpy(),\n",
    "            \"gt_lbl\"   : results[k][\"labels\"].cpu().numpy(),\n",
    "            \"gt_bbox\"  : results[k][\"boxes\"].cpu().numpy(),\n",
    "        }\n",
    "    return out_results\n",
    "\n",
    "def convert_submit_results(results):\n",
    "    out_results = {}\n",
    "    for k in results:\n",
    "        out_results[k] = {\n",
    "            \"labels\" : torch.from_numpy(results[k][\"dt_lbl\"]),\n",
    "            \"boxes\"  : torch.from_numpy(results[k][\"dt_bbox\"]),\n",
    "            \"scores\" : torch.from_numpy(results[k][\"dt_score\"])\n",
    "        }\n",
    "    return out_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sub_file(results, thr=.65, maxbbox=5, name=\"default\"):\n",
    "    print(id(results))\n",
    "    # Init path\n",
    "    path = f\"/home/tristan/road_project/workspace/Damage Detection/submissions/{name}\"\n",
    "    assert not os.path.isfile(path)\n",
    "    \n",
    "    # Filter results\n",
    "    filtered_results = {}\n",
    "    for key, anno in tqdm(results.items()):\n",
    "        filtered_results[key] = select_bboxes(anno, thr, maxbbox)\n",
    "    \n",
    "    #Format string\n",
    "    text_results = format_results(filtered_results, sep=\",\")\n",
    "\n",
    "    # Write results\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(text_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluation import iou_fn\n",
    "\n",
    "def eps(x):\n",
    "    return 10**-6 * np.random.randn(*x.shape)\n",
    "\n",
    "def nms(result, iou_thr = .1):\n",
    "    bbox = result[\"dt_bbox\"]\n",
    "    scores = result[\"dt_score\"] \n",
    "    scores+= eps(scores)\n",
    "    msk = np.ones_like(scores) > 0\n",
    "    a,b = np.where(iou_fn(bbox, bbox) > iou_thr)\n",
    "    a,b = a[a!=b], b[a!=b]\n",
    "    msk_idx = b[scores[a] > scores[b]]\n",
    "    msk[msk_idx] = False\n",
    "    return  {\n",
    "        \"gt_lbl\"  : result[\"gt_lbl\"],\n",
    "        \"gt_bbox\" : result[\"gt_bbox\"],\n",
    "        \"dt_bbox\" : result[\"dt_bbox\"][msk],\n",
    "        \"dt_score\": result[\"dt_score\"][msk],\n",
    "        \"dt_lbl\"  : result[\"dt_lbl\"][msk],\n",
    "    }\n",
    "\n",
    "def nms_all(results, iou_thr = .1):\n",
    "    return {k:nms(v, iou_thr) for k,v in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_workers = 1\n",
    "gpu_id = 1\n",
    "device = f\"cuda:{gpu_id}\"\n",
    "mode = \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpaths = {\n",
    "    \"base\":f\"./Torchvision/Checkpoints/Class types/{mode}/epoch_9\",\n",
    "    \"aug0\":f\"./Torchvision/Checkpoints/augmentation/{mode}/google_0/epoch_11\",\n",
    "    \"aug1\":f\"./Torchvision/Checkpoints/augmentation/{mode}/google_1/epoch_11\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2631 [00:00<?, ?it/s]/home/tristan/anaconda3/envs/detectron/lib/python3.8/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "100%|██████████| 2631/2631 [05:55<00:00,  7.40it/s]\n",
      "100%|██████████| 2631/2631 [05:53<00:00,  7.45it/s]\n",
      "100%|██████████| 2631/2631 [05:54<00:00,  7.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract results\n",
    "results = {}\n",
    "for k,model_path in modelpaths.items():\n",
    "    model = get_model_detection(5).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    res = get_test_outputs(model)\n",
    "    results[k]=convert_eval_format(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legacy ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2631/2631 [00:02<00:00, 910.31it/s]\n",
      "100%|██████████| 2631/2631 [00:00<00:00, 21176.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n"
     ]
    }
   ],
   "source": [
    "ensemble_results = ensemble_legacy(results, iou_thr=.5)\n",
    "ensemble_results = convert_submit_results(ensemble_results)\n",
    "extract_sub_file(ensemble_results, name=\"legacy_ensemble_iou=.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_sub_file(results[\"base\"], name=\"baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2631/2631 [00:00<00:00, 7802.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nms_results = nms_all(results[\"base\"], iou_thr=.5)\n",
    "nms_results = convert_submit_results(nms_results)\n",
    "extract_sub_file(nms_results, name=\"nms_baseline_ious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter results\n",
    "thr = .63\n",
    "maxbbox = 5\n",
    "filtered_results = {}\n",
    "lbls = []\n",
    "for key, anno in tqdm(ensemble_results.items()):\n",
    "    filtered_results[key] = select_bboxes(anno, thr, maxbbox)\n",
    "    lbls.extend(filtered_results[key][\"labels\"].cpu().numpy().tolist())\n",
    "    \n",
    "# Format\n",
    "text_results = format_results(filtered_results, sep=\",\")\n",
    "\n",
    "#name = f\"baseline_submission_{mode}_thr{thr}_maxbb{maxbbox}\"\n",
    "path = f\"/home/tristan/road_project/workspace/Damage Detection/submissions/{name}\"\n",
    "assert not os.path.isfile(path)\n",
    "with open(path, \"w\") as f:\n",
    "    f.write(text_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
